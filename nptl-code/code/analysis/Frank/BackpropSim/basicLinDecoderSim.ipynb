{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "nUnits = 50\n",
    "nSysState = 4\n",
    "nControl = 2\n",
    "nSteps = 250\n",
    "nInput = 2\n",
    "dt = 0.02\n",
    "delaySteps = 10\n",
    "\n",
    "initial = tf.truncated_normal([nUnits, nUnits], stddev=0.1)\n",
    "W = tf.Variable(initial)\n",
    "\n",
    "initial = numpy.random.normal(0,0.1,[nControl, nUnits])\n",
    "for i in range(nControl):\n",
    "    initial[i,:] = initial[i,:] / numpy.linalg.norm(initial[i,:])\n",
    "    initial[i,:] = initial[i,:] / numpy.sqrt(nUnits)\n",
    "U = tf.Variable(initial, dtype=tf.float32, trainable=False)\n",
    "\n",
    "initial = tf.truncated_normal([nUnits, nSysState], stddev=0.1)\n",
    "I = tf.Variable(initial)\n",
    "\n",
    "initial = tf.truncated_normal([nUnits, nInput], stddev=0.1)\n",
    "Iseq = tf.Variable(initial)\n",
    "\n",
    "initial = tf.truncated_normal([nUnits, 1], stddev=0.1)\n",
    "biases = tf.Variable(initial)\n",
    "\n",
    "A = tf.constant([[1, 0, dt, 0], [0, 1, 0, dt], [0, 0, 0.96, 0], [0, 0, 0, 0.96]])\n",
    "B = tf.constant([[0, 0],[0, 0],[0.04, 0],[0, 0.04]])\n",
    "\n",
    "startNetState = tf.placeholder(tf.float32, shape=[nUnits, 1])\n",
    "startSysState = tf.placeholder(tf.float32, shape=[nSysState, 1])\n",
    "inSeq = tf.placeholder(tf.float32, shape=[nInput, nSteps, 1])\n",
    "targSeq = tf.placeholder(tf.float32, shape=[nInput, nSteps, 1])\n",
    "\n",
    "#unfold RNN + linear system in time\n",
    "netStates = [startNetState]\n",
    "sysStates = [startSysState]\n",
    "controlOut = []\n",
    "for i in range(nSteps):\n",
    "    netStates.append(tf.tanh(biases + tf.matmul(W, netStates[i]) + tf.matmul(Iseq, inSeq[:,i,:]) + tf.matmul(I, sysStates[i])))\n",
    "    controlOut.append(tf.matmul(U, netStates[i]))\n",
    "    sysStates.append(tf.matmul(A, sysStates[i]) + tf.matmul(B, controlOut[-1]))\n",
    "    tf.add_to_collection('PosErr',tf.square(sysStates[-1][0:2]-targSeq[:,i,:]))\n",
    "\n",
    "totalErr = tf.reduce_sum(tf.add_n(tf.get_collection('PosErr'), name='total_err'))\n",
    "\n",
    "learnRate = tf.Variable(1.0, trainable=False)\n",
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(totalErr, tvars), 1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learnRate)\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars),\n",
    "    global_step=tf.contrib.framework.get_or_create_global_step())\n",
    "new_lr = tf.placeholder(tf.float32, shape=[], name=\"new_learning_rate\")\n",
    "lr_update = tf.assign(learnRate, new_lr)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "initNet = numpy.zeros([nUnits, 1]) \n",
    "trainSteps = 1000\n",
    "\n",
    "for i in range(trainSteps):\n",
    "    #learn rate\n",
    "    lr = 1 - i/trainSteps\n",
    "    \n",
    "    #random start state and target\n",
    "    initSys = numpy.random.normal(0,1,[4,1])\n",
    "    randTarg = numpy.random.normal(0,1,[2,1])\n",
    "    randTargSeq = numpy.reshape(numpy.tile(randTarg, [1,nSteps]),[2,nSteps,1])\n",
    "    \n",
    "    #descend gradient\n",
    "    ao, to, te = sess.run([lr_update, train_op, totalErr], feed_dict={new_lr: lr, startNetState: initNet, startSysState: initSys, inSeq: randTargSeq, targSeq: randTargSeq})\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(\"step %d, training accuracy %g\"%(i, te))\n",
    "\n",
    "#plot trajectory        \n",
    "randTarg1 = numpy.random.normal(0,1,[2,1])\n",
    "randTarg2 = numpy.random.normal(0,1,[2,1])\n",
    "randTargSeq1 = numpy.reshape(numpy.tile(randTarg1, [1,50]),[2,50,1])\n",
    "randTargSeq2 = numpy.reshape(numpy.tile(randTarg2, [1,50]),[2,50,1])\n",
    "randTargSeq = numpy.hstack((randTargSeq1, randTargSeq2))    \n",
    "    \n",
    "sysTraj, controlTraj, netTraj = sess.run([sysStates, controlOut, netStates], feed_dict={new_lr: lr, startNetState: initNet, startSysState: initSys, inSeq: randTargSeq, targSeq: randTargSeq})\n",
    "sysTraj = numpy.hstack(sysTraj)\n",
    "controlTraj = numpy.hstack(controlTraj)\n",
    "netTraj = numpy.hstack(netTraj)\n",
    "\n",
    "plt.plot(sysTraj[0,:], sysTraj[1,:])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(sysTraj.transpose())\n",
    "plt.show()\n",
    "\n",
    "plt.plot(controlTraj.transpose())\n",
    "plt.show()\n",
    "\n",
    "plt.plot(netTraj.transpose())\n",
    "plt.show()\n",
    "\n",
    "fWriter = tf.summary.FileWriter('C:/Users/Frank/Documents/PythonScripts/linSys/tboard/', sess.graph)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
