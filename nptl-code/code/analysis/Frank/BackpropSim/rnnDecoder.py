#hyperparameters to search:
#dropout, L2 weight regularization
#learning rate schedule
#number of units
#magnitude of weight initialization
#smoothing on input features
#number of time-steps per series

#objects of specific inquiry:
#number of factors on input layer, pre-solved input layer restricted to subsets of 4-component model
#training over multiple datasets & subjects; variable input layer, input layer + context key, retrain whole model
#stacking multiple recurrent layers
#vanilla vs. GRU vs. LSTM

#compare to:
#linear velocity decoder with exponential smoothing & fixed delay
#VKF with fixed delay
#Weiner filter velocity decoder
#Magnitude decoder

import scipy.io
import numpy as np
import tensorflow as tf
import argparse
import os
import errno
from customRnnCells import ContextGRUCell, ContextRNNCell, ContextLSTMCell, initializeWeights, makelambda

#parse inputs
parser = argparse.ArgumentParser(description='RNN decoder with multi-dataset training')
parser.add_argument('--datasets', metavar='datasets', type=str, nargs='+',
                    help='a list of dataset numbers to include in training')
parser.add_argument('--datasetDir', metavar='datasetDir', type=str, nargs=1,
                    help='dataset directory')
parser.add_argument('--outputDir', metavar='outputDir', type=str, nargs=1,
                    help='output directory')

hyperParams = [['rnnType', str],
               ['device',str],
               ['nLayers', int],
               ['nDecInputFactors', int],
               ['L2Reg', float],
               ['learnRateStart',float],
               ['nEpochs',int],
               ['initWeightScale',float],
               ['useInputProj',int],
               ['nDecUnits',int],
               ['keepProbIn',float],
               ['keepProbLayer',float]]
for i in range(len(hyperParams)):
    parser.add_argument('--'+hyperParams[i][0], metavar=hyperParams[i][0], type=hyperParams[i][1], nargs=1)

args = parser.parse_args()
#args = parser.parse_args(['--datasets','t5.2016.09.28',
#                          '--datasetDir','/Users/frankwillett/Data/Derived/rnnDecoding_2dDatasets/4comp_2/Fold1',
#                          '--outputDir','/Users/frankwillett/Data/Derived/gruTestOut','--rnnType','RNN',
#                          '--nLayers','2','--nDecInputFactors','2','--L2Reg','100','--learnRateStart','0.01','--nEpochs','2000',
#                          '--initWeightScale','1.0','--nDecUnits','50','--useInputProj','0','--keepProbIn','1.0','--keepProbLayer','0.95','--device','/cpu:0'])
print(vars(args))

try:
    os.makedirs(args.outputDir[0])
except OSError as exception:
    if exception.errno != errno.EEXIST:
        raise
        
doPlot = False
if doPlot:
    import matplotlib.pyplot as plt
        
#Input & Targets generated by MATLAB
inputs = []
targets = []
inputsVal = []
targetsVal = []
inputsFinal = []
targetsFinal = []

totalTrials = 0
for datasetName in args.datasets:
    rnnData = scipy.io.loadmat(args.datasetDir[0] + '/' + datasetName + '.mat')
    inputs.append(rnnData['inputs'].astype(np.float32))
    targets.append(rnnData['targets'].astype(np.float32))
    inputsVal.append(rnnData['inputsVal'].astype(np.float32))
    targetsVal.append(rnnData['targetsVal'].astype(np.float32))
    inputsFinal.append(rnnData['inputsFinal'].astype(np.float32))
    targetsFinal.append(rnnData['targetsFinal'].astype(np.float32))
    
    print(str(rnnData['inputs'].shape[0]) + ' trials from ' + datasetName)
    totalTrials += rnnData['inputs'].shape[0]
    
print(str(totalTrials) + ' total trials from ' + str(len(args.datasets)) + ' datasets')

nDatasets = len(inputs)
nSteps = inputs[0].shape[1]
nTargets = targets[0].shape[2]
batchSize = 32

if args.rnnType[0]=='LSTM':
    rnnCell = ContextLSTMCell
elif args.rnnType[0]=='GRU':
    rnnCell = ContextGRUCell
elif args.rnnType[0]=='RNN':
    rnnCell = ContextRNNCell
    
#Start tensorflow
config = tf.ConfigProto(allow_soft_placement=True,
              log_device_placement=False)
sess = tf.Session(config=config)

with tf.device(args.device[0]):
    #these placeholders must be configured for each new batch
    batchTargets = tf.placeholder(tf.float32, shape=[batchSize, nSteps, nTargets])
    startDecState = tf.placeholder(tf.float32, shape=[args.nDecUnits[0], batchSize])
    errorMask = tf.placeholder(tf.float32, shape=[batchSize, nSteps])
    datasetIdx = tf.placeholder(tf.int32, shape=[])
    keep_prob_input = tf.placeholder(tf.float32, [], "keep_prob")
    keep_prob_layer = tf.placeholder(tf.float32, [], "keep_prob")
    
    #multi-layered RNN decoder
    decLayers = []
    for i in range(args.nLayers[0]):
        if i==0:
            nLayerInputs = args.nDecInputFactors[0]
            kp = tf.constant(1.0)
        else:
            nLayerInputs = args.nDecUnits[0]
            kp = keep_prob_layer
            
        newLayer = rnnCell(args.nDecUnits[0], nLayerInputs, 'RNN_layer'+str(i), datasetIdx, numContexts=nDatasets, reset_bias=1.0, update_bias=-1.0, weight_scale=1.0,
                       clip_value=np.inf, input_keep_prob=kp)
        decLayers.append(newLayer)
    
    #input projection
    if args.useInputProj[0]:
        projW = []
        projB = []
        for i in range(nDatasets):
            with tf.variable_scope('ProjLayer'):
                projW.append(tf.get_variable("W_"+str(i), dtype=tf.float32, 
                        initializer=initializeWeights([inputs[i].shape[2], args.nDecInputFactors[0] ], 1.0), trainable=True))
                projB.append(tf.get_variable("b_"+str(i), [1, args.nDecInputFactors[0]], dtype=tf.float32, 
                        initializer=tf.zeros_initializer, trainable=True))
            
        #project dynamically
        predW = []
        predB = []
        for i in range(nDatasets):   
            predW.append((tf.equal(datasetIdx, tf.constant(i)), makelambda(projW[i])))
            predB.append((tf.equal(datasetIdx, tf.constant(i)), makelambda(projB[i])))
        activeProjW = tf.case(predW, default=makelambda(projW[0]))    
        activeProjB = tf.case(predB, default=makelambda(projB[0]))    
        
        batchInputs = tf.placeholder(tf.float32, shape=[batchSize, nSteps, None])
        projectedInput = tf.matmul(batchInputs, tf.tile(tf.expand_dims(activeProjW,0),[batchSize, 1, 1])) + activeProjB
    else:
        batchInputs = tf.placeholder(tf.float32, shape=[batchSize, nSteps, args.nDecInputFactors[0]])
        projectedInput = batchInputs
        
    if args.keepProbIn[0]!=1.0:
        projectedInput = tf.nn.dropout(projectedInput, keep_prob_input)
    
    #unfold RNN in time
    if args.nLayers[0]==1:
        cellToUse = decLayers[0]
    else:
        cellToUse = tf.nn.rnn_cell.MultiRNNCell(decLayers)
        
    decStates, lastState = tf.nn.dynamic_rnn(
        cell = cellToUse,
        dtype = tf.float32,
        inputs = projectedInput,
    )
            
    #readout the target
    W_o = tf.get_variable("W_o", dtype=tf.float32, 
                    initializer=initializeWeights([args.nDecUnits[0], nTargets ], 1.0), trainable=True)
    b_o = tf.get_variable("b_o", [1, nTargets], dtype=tf.float32, 
                    initializer=tf.zeros_initializer, trainable=True)
    if args.keepProbLayer[0]!=1.0:
        decStates = tf.nn.dropout(decStates, keep_prob_layer)
    decOutput = tf.matmul(decStates, tf.tile(tf.expand_dims(W_o,0),[batchSize, 1, 1])) + b_o
    
    #error function
    err = tf.multiply(tf.reduce_sum(tf.square(batchTargets - decOutput),2), errorMask)
    totalErr = tf.sqrt(tf.reduce_mean(err))
    
    trainErr_ph = tf.placeholder(tf.float32, shape=[])
    testErr_ph = tf.placeholder(tf.float32, shape=[])
    trainErrSummary = tf.summary.scalar('train_RMSE', trainErr_ph)
    testErrSummary = tf.summary.scalar('test_RMSE', testErr_ph)
    
    #add l2 cost
    l2vars = []
    if args.useInputProj[0]:
        l2vars.append(activeProjW)
    l2vars.append(W_o)  
    for i in range(args.nLayers[0]):
        l2vars.extend(decLayers[i]._weightVariables)
      
    l2cost = tf.constant(0.0)
    total_params = 0
    for i in range(len(l2vars)):
      shape = l2vars[i].get_shape().as_list()
      if shape[0]!=None:
          total_params += np.prod(shape)
      l2cost += tf.nn.l2_loss(l2vars[i])
    l2cost = l2cost / total_params
    l2cost = l2cost * args.L2Reg[0]
    
    l2cost_ph = tf.placeholder(tf.float32, shape=[])
    l2costSummary = tf.summary.scalar('l2cost', l2cost_ph)
    
    #total cost
    totalCost = l2cost + totalErr
    
    #prepare gradients and optimizer
    tvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
    learnRate = tf.Variable(1.0, trainable=False)
    
    grads = tf.gradients(totalCost, tvars)
    grads, grad_global_norm = tf.clip_by_global_norm(grads, 200)
    opt = tf.train.AdamOptimizer(learnRate, beta1=0.9, beta2=0.999,
                                 epsilon=1e-01)
    train_op = opt.apply_gradients(
        zip(grads, tvars), global_step=tf.contrib.framework.get_or_create_global_step())
        
    new_lr = tf.placeholder(tf.float32, shape=[], name="new_learning_rate")
    lr_update = tf.assign(learnRate, new_lr)
    
    #prepare dropout probabilities
    kpi = args.keepProbIn[0]
    kpl = args.keepProbLayer[0]
    
    #prepare tensorboard
    writer = tf.summary.FileWriter(args.outputDir[0])
    
    #prepare to save the model
    saver = tf.train.Saver()
    lve = np.inf
    
    #How many parameters does this model have?
    total_params = 0
    for i in range(len(tvars)):
      shape = tvars[i].get_shape().as_list()
      nParams = np.prod(shape)
      print(tvars[i].name + ': ' + str(nParams))
      total_params += nParams
    print("Total model parameters: ", total_params)
    
    sess.run(tf.global_variables_initializer())
    
    #train RNN one batch at a time
    prevStartStates = np.zeros([args.nDecUnits[0], batchSize])
    bestEpoch = 0
    
    for i in range(args.nEpochs[0]):
        #learn rate
        lr = args.learnRateStart[0]*(1 - i/float(args.nEpochs[0]))
        
        #shuffle dataset order
        errListTrain = []
        datasetOrder = np.random.permutation(nDatasets)
        for currentDatasetIdx in datasetOrder:
            nTrials = inputs[currentDatasetIdx].shape[0]
            trialOrder = np.random.permutation(nTrials)
            
            eMask = np.concatenate((np.zeros([batchSize, 100]), np.ones([batchSize, nSteps-100])), 1)
            nBatches = int(np.ceil(float(nTrials)/batchSize))
            for batchIdx in range(nBatches):
                selIdx = np.arange(batchIdx*batchSize, (batchIdx+1)*batchSize)
                selIdx = selIdx[selIdx<nTrials]
                if len(selIdx)<batchSize:
                    selIdx = np.concatenate([selIdx, np.zeros([batchSize-len(selIdx)])])
                    selIdx = selIdx.astype(np.int32)
                    eMask[0:len(selIdx),:]=float(batchSize)/len(selIdx)
                    eMask[len(selIdx):,:]=0
            
                #random start state and target
                trlIdx = trialOrder[selIdx]
                inputSeq = inputs[currentDatasetIdx][trlIdx,:,:]
                targSeq = targets[currentDatasetIdx][trlIdx,:,:]
                
                #descend gradient
                ao, to, te = sess.run([lr_update, train_op, totalErr], 
                                                    feed_dict={new_lr: lr, startDecState: prevStartStates, batchInputs: inputSeq, 
                                                               batchTargets: targSeq, datasetIdx: currentDatasetIdx, errorMask: eMask, keep_prob_input: kpi, keep_prob_layer: kpl})
                errListTrain.append(te)
    
        #track validation accuracy on a random validation batch
        eMask = np.concatenate((np.zeros([batchSize, 100]), np.ones([batchSize, nSteps-100])), 1)
        errListVal = []
        for currentDatasetIdx in range(nDatasets):
            nTrials = inputsVal[currentDatasetIdx].shape[0]
            valIdx = np.random.choice(nTrials, batchSize)
            inputSeq = inputsVal[currentDatasetIdx][valIdx,:,:]
            targSeq = targetsVal[currentDatasetIdx][valIdx,:,:]
            te, l2c = sess.run([totalErr, l2cost], feed_dict={new_lr: lr, startDecState: prevStartStates, batchInputs: inputSeq, batchTargets: targSeq, 
                                       datasetIdx: currentDatasetIdx, errorMask: eMask, keep_prob_input: 1.0, keep_prob_layer: 1.0})
            errListVal.append(te)
        
        #log progress
        mnErrTrain = np.mean(errListTrain)
        mnErrVal = np.mean(errListVal)
        testSummary, trainSummary, l2cSummary = sess.run([testErrSummary, trainErrSummary, l2costSummary], feed_dict={trainErr_ph: mnErrTrain, testErr_ph: mnErrVal, l2cost_ph: l2c})
        writer.add_summary(trainSummary, i)
        writer.add_summary(testSummary, i)
        writer.add_summary(l2cSummary, i)
        
        #save whenever validation error is at its lowest point so far
        if mnErrVal < lve:
            bestEpoch = i
            lve = mnErrVal
            saver.save(sess, args.outputDir[0] + '/model.ckpt', global_step=i, write_meta_graph=False)
        
        #validation plot every once in a while
        if i%5 == 0:
            print('Epoch: ' + str(i) + ', trainErr: ' + str(mnErrTrain) + ', testErr: ' + str(mnErrVal))
                    
            if doPlot:
                plt.figure()
                for x in range(nDatasets):
                    inputSeq = inputsVal[x][np.zeros(batchSize,dtype=int),:,:]
                    targSeq = targetsVal[x][np.zeros(batchSize,dtype=int),:,:]
                    do, inf = sess.run([decOutput, projectedInput], feed_dict={new_lr: lr, startDecState: prevStartStates, batchInputs: inputSeq, batchTargets: targSeq,
                                           datasetIdx: x, errorMask: eMask, keep_prob_input: 1.0, keep_prob_layer: 1.0})
                    do = np.stack(do)
                    inf = np.stack(inf)
                
                    plt.subplot(nDatasets,2,x*2+1)
                    plt.plot(targetsVal[x][0,:,0])
                    plt.plot(do[0,:,0])
                    
                    plt.subplot(nDatasets,2,x*2+2)
                    plt.plot(targetsVal[x][0,:,1])
                    plt.plot(do[0,:,1])
                plt.show()
    
    #load the best performing variables
    ckpt = tf.train.get_checkpoint_state(args.outputDir[0])
    saver.restore(sess, ckpt.model_checkpoint_path)
    
    #apply to inputsFinal and return
    finalIdx = np.array(range(batchSize))
    outputs = []
    inFac = []
    
    for currentDatasetIdx in range(nDatasets):
        nTrials = inputsFinal[currentDatasetIdx].shape[0]
        outputs.append(np.zeros(targetsFinal[currentDatasetIdx].shape))
        inFac.append(np.zeros([nTrials, nSteps, args.nDecInputFactors[0]]))
        
        nBatches = int(np.ceil(float(nTrials)/batchSize))
        for batchIdx in range(nBatches):
            selIdx = np.arange(batchIdx*batchSize, (batchIdx+1)*batchSize)
            selIdx = selIdx[selIdx<nTrials]
            if len(selIdx)<batchSize:
                selIdx = np.concatenate([selIdx, np.zeros([batchSize-len(selIdx)])])
                selIdx = selIdx.astype(np.int32)
        
            inputSeq = inputsFinal[currentDatasetIdx][selIdx,:,:]
            targSeq = targetsFinal[currentDatasetIdx][selIdx,:,:]
            
            do, infa = sess.run([decOutput, projectedInput], feed_dict={new_lr: lr, startDecState: prevStartStates, batchInputs: inputSeq, 
                                                           batchTargets: targSeq, datasetIdx: currentDatasetIdx, errorMask: eMask, keep_prob_input: 1.0, keep_prob_layer: 1.0})
        
            outputs[currentDatasetIdx][selIdx,:,:] = do
            inFac[currentDatasetIdx][selIdx,:,:] = infa

if doPlot:        
    plt.figure()
    for x in range(3):
        plt.subplot(3,2,x*2+1)
        plt.plot(targetsFinal[0][x,:,0])
        plt.plot(outputs[0][x,:,0])
        
        plt.subplot(3,2,x*2+2)
        plt.plot(targetsFinal[0][x,:,1])
        plt.plot(outputs[0][x,:,1])
    plt.show()
                
a = {}
a['bestEpoch']=bestEpoch
for currentDatasetIdx in range(nDatasets):
    a['targetsFinal'+str(currentDatasetIdx)]=targetsFinal[currentDatasetIdx]
    a['outputsFinal'+str(currentDatasetIdx)]=outputs[currentDatasetIdx]
    a['inFacFinal'+str(currentDatasetIdx)]=inFac[currentDatasetIdx]
scipy.io.savemat(args.outputDir[0] + '/finalOutput',a)
